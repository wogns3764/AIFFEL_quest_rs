{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40038565-2595-4d8f-a3f2-61b00e87c5d3",
   "metadata": {},
   "source": [
    "## #사용할 도구 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94975a64-3417-45e1-9ba8-caadced35c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7e336-4cb7-43fb-b33d-165f467c1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fde75e-049c-4b90-8668-92d4dddb6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ae4ab-b12d-48d4-95c5-91a7e9c14d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.OxfordIIITPet(root='./data', split=\"trainval\", target_types=\"category\", download=True, transform=transform)\n",
    "testset = torchvision.datasets.OxfordIIITPet(root='./data', split=\"test\", target_types=\"category\", download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251c51e-a7f7-4bd4-a5ab-34189c82b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = trainset[0]\n",
    "\n",
    "print(f'image shape: {image.shape}')\n",
    "print(f'label: {label}')\n",
    "print(f'Number of classes : {len(trainset.classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92319d9-1abe-4434-bbd1-bf81679b6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = torch.tensor(len(trainset))\n",
    "test_size = torch.tensor(len(testset))\n",
    "\n",
    "num_classes = len(trainset.classes)\n",
    "class_names = trainset.classes\n",
    "\n",
    "\n",
    "print(num_classes)\n",
    "print(class_names)\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17a201-dfad-413b-a597-90ec947e52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "  img = img / 2 + 0.5\n",
    "  npimg = img.numpy()\n",
    "  return np.transpose(npimg, (1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfac9b-6eea-4788-9fc4-4fe3fb41b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_multiple_images(dataset, n_images=9):\n",
    "  dataiter = iter(dataset)\n",
    "  images, labels = next(dataiter)\n",
    "  fig, axes = plt.subplots(3, 3, figsize=(6,6))\n",
    "  axes = axes.flatten()\n",
    "\n",
    "\n",
    "  for i in range(n_images):\n",
    "    ax = axes[i]\n",
    "    img = imshow(images[i])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"Label: {trainset.classes[labels[i]]}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c500ba1-208e-45c5-aa94-1561513c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_images(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4434b-a95d-4485-84c0-3f88b0ed9a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_images(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344c771-53ab-4523-b90e-8595746090cf",
   "metadata": {},
   "source": [
    "### Basic Block(Resnet-34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec326c4-1f0b-48e4-8773-5161d8a0473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, use_skip_connection=True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection # 스위치 저장\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # 스위치를 이용하여 Plainnet일때는 skip connection 꺼줌\n",
    "        if self.use_skip_connection:\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efdda64-df36-4522-b3de-288a9dd5467d",
   "metadata": {},
   "source": [
    "### Bottleneck Block(Resnet-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd51ad-cce9-49c4-9be2-99e4e082cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, use_skip_connection=True):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection # 스위치 저장\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "\n",
    "        # 스위치를 이용하여 Plainnet일때는 skip connection 꺼줌\n",
    "        if self.use_skip_connection:\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e771ae4-fa50-48a9-ae42-4c53d4142ced",
   "metadata": {},
   "source": [
    "## Resnet 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b8338-bee2-472e-ac81-69274a6a905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=37, use_skip_connection=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.use_skip_connection = use_skip_connection # 전체 모델 설정 저장\n",
    "\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "  \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "\n",
    "\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample, use_skip_connection=self.use_skip_connection))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels, use_skip_connection=self.use_skip_connection))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd9e2a-a329-4544-9556-d8b313b2d160",
   "metadata": {},
   "source": [
    "## resnet34,50과 Plainnet모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af845b4-d704-4e05-928f-180ced7c9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34(num_classes=37):\n",
    "\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, use_skip_connection=True)\n",
    "\n",
    "def resnet50(num_classes=37):\n",
    "\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, use_skip_connection=True)\n",
    "\n",
    "def build_plainnet(model_name, num_classes=37):\n",
    " \n",
    "    if model_name == 'plain34':\n",
    "        return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, use_skip_connection=False)\n",
    "    elif model_name == 'plain50':\n",
    "        return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, use_skip_connection=False)\n",
    "    else:\n",
    "        raise ValueError(\"Choose model_name between 'plain34' and 'plain50'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 입력 이미지 (224, 224, 3) -> Batch size 포함 (1, 3, 224, 224)\n",
    "    dummy_input = torch.randn(1, 3, 224, 224)\n",
    "    \n",
    "    # 1. ResNet-34 생성 및 확인\n",
    "    model_resnet34 = resnet34()\n",
    "    output_resnet = model_resnet50(dummy_input)\n",
    "    print(f\"[ResNet-34] Output Shape: {output_resnet.shape}\")\n",
    "    \n",
    "    # 2. ResNet-50 생성 및 확인\n",
    "    model_resnet50 = resnet50()\n",
    "    output_resnet = model_resnet50(dummy_input)\n",
    "    print(f\"[ResNet-50] Output Shape: {output_resnet.shape}\") # (1, 37)\n",
    "\n",
    "    # 3. PlainNet-50 생성 및 확인\n",
    "    model_plain50 = build_plainnet('plain50')\n",
    "    output_plain = model_plain50(dummy_input)\n",
    "    print(f\"[PlainNet-50] Output Shape: {output_plain.shape}\") # (1, 37)\n",
    "\n",
    "    # 4. PlainNet-34 생성 및 확인\n",
    "    model_plain34 = build_plainnet('plain34')\n",
    "    output_plain34 = model_plain34(dummy_input)\n",
    "    print(f\"[PlainNet-34] Output Shape: {output_plain34.shape}\") # (1, 37)\n",
    "\n",
    "    print(\"\\n모델완성!\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7f392-17e3-4f02-88aa-5b88749c4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_34 = resnet34(num_classes=1000)\n",
    "summary(ResNet_34, input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e49f2-f5fb-4a01-ae5d-b0e2778e37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_50 = resnet50(num_classes=1000)\n",
    "summary(ResNet_50, input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9249a-c1ec-494f-9b43-3f831e3c589a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ced604-e1c3-4d8c-a5d9-3b52fc6ce525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5897d69-6ecf-4285-8210-3140b1bfe890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCH = 15\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9744cf-c23b-4efb-8028-ddc413bdcab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "current_time = time.time()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model_resnet34 = resnet34(num_classes=37).to(device)\n",
    "\n",
    "\n",
    "for param in model_resnet34.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_resnet34.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "resnet34_train_losses = []\n",
    "resnet34_val_accuracies = []\n",
    "\n",
    "print(\"ResNet-34 학습 시작...\")\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # --- 학습 (Train) ---\n",
    "    model_resnet34.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model_resnet34(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "\n",
    "    resnet34_epoch_loss = loss.item()\n",
    "    resnet34_train_acc = 100 * correct / total\n",
    "\n",
    "\n",
    "    resnet34_train_losses.append(resnet34_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCH}] Train Loss: {resnet34_epoch_loss:.4f}, Train Acc: {resnet34_train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "    model_resnet34.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_resnet34(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    resnet34_val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCH}] Validation Acc: {val_acc:.2f}%\")\n",
    "\n",
    "print(f\"Total Training time: {time.time() - current_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7bc50-bae0-4d49-909c-dea3c82b821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plain34 = build_plainnet('plain34', num_classes=37).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model_plain34.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "plain34_train_losses = []\n",
    "plain34_val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "    model_plain34.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_plain34(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    plain34_train_losses.append(epoch_loss)\n",
    "\n",
    "    print(f\"[PlainNet] Epoch [{epoch+1}/{EPOCH}] Loss: {epoch_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "    model_plain34.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_plain34(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    plain34_val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"[PlainNet] Epoch [{epoch+1}/{EPOCH}] Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"PlainNet 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e32ff-ddec-4fca-baf0-e38e6623cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 1. 학습 Loss 비교 (낮을수록 좋음)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(resnet34_train_losses, label='ResNet-34', color='blue')\n",
    "plt.plot(plain34_train_losses, label='PlainNet-34', color='red', linestyle='--')\n",
    "plt.title('Model Training Loss Comparison')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5929dc-7e7b-43e1-9c4c-868ec1b6e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resnet34_val_accuracies, label='ResNet-34', color='blue')\n",
    "plt.plot(plain34_val_accuracies, label='PlainNet-34', color='red', linestyle='--')\n",
    "plt.title('Validation Accuracy Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061532a-8ce9-4064-9d7c-9f02b2f83d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_resnet50 = resnet50(num_classes=37).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model_resnet50.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "resnet50_train_losses = []\n",
    "resnet50_val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "   \n",
    "    model_resnet50.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    resnet50_train_losses.append(epoch_loss)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"[ResNet-50] Epoch [{epoch+1}/{EPOCH}] Loss: {epoch_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "    \n",
    "    model_resnet50.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_resnet50(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    resnet50_val_accuracies.append(val_acc)\n",
    "    print(f\"            Validation Acc: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"ResNet-50 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893dc56-ba54-413f-b98e-2fcf6e5949c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_plain50 = build_plainnet('plain50', num_classes=37).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model_plain50.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "plain50_train_losses = []\n",
    "plain50_val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    model_plain50.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_plain50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    plain50_train_losses.append(epoch_loss)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"[PlainNet-50] Epoch [{epoch+1}/{EPOCH}] Loss: {epoch_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "    \n",
    "    model_plain50.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_plain50(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    plain50_val_accuracies.append(val_acc)\n",
    "    print(f\"              Validation Acc: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"PlainNet-50 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10054bc5-467b-4676-9022-0cbb68560d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(resnet50_train_losses, label='ResNet-50', color='blue')\n",
    "plt.plot(plain50_train_losses, label='PlainNet-50', color='red', linestyle='--')\n",
    "plt.title('Training Loss Comparison (50 Layers)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f622f-5adf-46fd-850e-8aa74879c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resnet50_val_accuracies, label='ResNet-50', color='blue')\n",
    "plt.plot(plain50_val_accuracies, label='PlainNet-50', color='red', linestyle='--')\n",
    "plt.title('Validation Accuracy Comparison (50 Layers)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4fa6f-e2e5-4be8-8a5b-b8ab00302fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
